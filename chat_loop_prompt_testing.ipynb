{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Test Prompt Tips by Chatting with the LLM leadership coach"
      ],
      "metadata": {
        "id": "voYkopHcGZiC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaJ_bAo4DXJa"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "import os\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i82qlrAVDXJc"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    api_key=API_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chat_completion(messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model=LLM_Model,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        # max_tokens=500,\n",
        "        top_p=0.5,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=None\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "lMQp9uUoFzsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6Eb5dowDXJd"
      },
      "outputs": [],
      "source": [
        "system_instruction = \"\"\"\n",
        "As a leadership coach, your primary role is to guide the leader towards self-discovery so they can discover their own solutions. Please follow these guidelines during the interaction:\n",
        "\n",
        "...omitted prompt tips...\n",
        "\n",
        "Your response should follow this format:\n",
        "response:\n",
        "certainty:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7EJb0jZDXJd"
      },
      "outputs": [],
      "source": [
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": system_instruction}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Chat Loop to Test Current Prompt Tips"
      ],
      "metadata": {
        "id": "IswbPpzqHbkd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV1PfLUEDXJd"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting the chat.\")\n",
        "        break\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    ai_response = get_chat_completion(conversation_history)\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "    print(\"AI: \", ai_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNvs1DAnDXJd"
      },
      "outputs": [],
      "source": [
        "conversation_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgYw8ov7DXJd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('Prompt_testing_transcripts.json', 'w', encoding='utf-8') as file:\n",
        "    json.dump(conversation_history, file, ensure_ascii=False, indent=4)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "68c46620193ef95b122b2567699a0018ca7cc4e872ffd9d39cfeb4c4c0222059"
    },
    "kernelspec": {
      "display_name": "Python 3.7.2 ('cse160')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}