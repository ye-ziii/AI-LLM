# Yezi's AI/LLM Projects

## About
A passionate data scientist dedicated to unlocking the power of data and exploring AI-driven solutions. 

Data-relevant working experience in a variety of industries, ranging from SaaS, Fintech, Consulting, and Education. Solid programming foundations with Python, R, SQL, Tableau, and Power BI with the combination of business capabilities of building KIP systems and dashboards, presenting data insights to non-technical stakeholders, and fostering interpersonal communication with clients and cross-functional teams.

Keen interest and passion in Machine Learning, NLP, and AI technology. Hands-on experience conducting statistical analysis, applying ML techniques, and building LLMs and AI-relevant applications.

## Education							       		
- M.S., Applied Data Science	| The University of Chicago (_December 2024_)	 			        		
- B.S., Economics & Business | The University of Washington (_June 2023_)

## Code Notebooks
#### _(Important Note: for the purpose of data & company privacy, the projects below are modified to contain some pseudo-code, but the workflows and logic are the same.)_

### **"LLM_with_context.ipynb"**
This notebook aims to prompt LLM to generate responses to the user's/leader's queries based on all the previous conversation contexts. It applies prompt engineering to test the effectiveness of a specific prompt tip version for the LLM.

### **"LLM_without_context.ipynb"**
This notebook aims to prompt LLM to generate responses to the user's/leader's queries WITHOUT providing the previous conversation contexts. It applies prompt engineering to test the effectiveness of a specific prompt tip version for the LLM.

### **"BLEU_evaluation.ipynb"**
This notebook evaluates the LLM response by comparing its similarity to the ground truth response(human coach response). Specifically, it uses the BLEU score metric.

### **"GPT4_Evaluation.ipynb"**
This notebook uses GPT4 as the LLM evaluator to evaluate different LLM responses against the ground truth response(human coach response) following a series of evaluation metrics. It gives the preference and corresponding reason. It helps automate the evaluation process and reduce human manual evaluation.

### **"chat_loop_prompt_testing.ipynb"**
This notebook creates an interactive chat loop for users to interact with the LLM leadership coach to test its performance against certain standards, assess the effectiveness of the prompt tips, etc.
